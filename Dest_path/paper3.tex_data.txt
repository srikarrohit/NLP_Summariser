paper3.tex_data.txt	Property Invariant Embedding for Automated Reasoning	{"Introduction": ["\r\n\r\nAutomated Theorem Provers (ATPs) DBLP:books/el/RobinsonV01 can be in principle\r\nused to attempt the proof of any provable mathematical conjecture. \r\nThe standard ATP approaches have\r\nso far relied primarily on fast implementation of manually designed search procedures and heuristics.\r\nHowever, using machine learning for guidance in the vast action spaces of the ATP calculi is a\r\nnatural choice that has been recently shown to significantly improve over the \r\nunguided systems KaliszykUMO18,JakubuvU19.\r\n\r\nThe common procedure of a firstorder ATP system -- saturation-style\r\nor tableaux -- is the following. The ATP starts with a set of first\r\norder axioms and a conjecture. The conjecture is negated and the\r\nformulas are Skolemized and clausified.\r\nThe objective is then to derive a contradiction from the set of clauses,\r\ntypically using some form of resolution and related inference rules.\r\nThe Skolemization as well as introduction of new definitions during\r\nthe clausification results in the introduction of many new function and predicate\r\nsymbols.\r\n\r\nWhen guiding the proving process by statistical machine learning, \r\nthe state of the prover and the\r\nformulas, literals, and clauses, are typically encoded  to vectors of\r\nreal numbers. This has been so far mostl  done with hand-crafted features resulting\r\nin large sparse vectors DBLP:conf/ijcai/KaliszykUV15,hammers4qed,abs-1108-3446,UrbanVS11,KaliszykU15,JakubuvU17a, possibly reducing their dimension afterwards ChvalovskyJ0U19. \r\nSeveral experiments with neural\r\nnetworks have been made recently, in particular based on 1D convolutions,\r\nRNNs GollerK96, TreeRNNs ChvalovskyJ0U19, and GraphNNs DuvenaudMABHAA15. Most of the approaches, however, cannot\r\ncapture well the idea of a variable occurring multiple times in the\r\nformula and to abstract from the names of the variables.\r\nThese issues were first \r\naddressed in FormulaNet DBLP:conf/nips/WangTWD17 but even that\r\narchitecture relies on knowing the names of function and predicate symbols. This makes it \r\nunsuitable for hand ing the large number of problem-specific function and predicate\r\nsymbols introduced during the cla sification.[The ratio of such symbols in real-world clausal datasets is around 40%, see Section ||SYMBOLTOKEN|| same holds for large datasets of ATP problems\r\nwhere symbol names are not used consistently, such as the TPTP library Sutcliffe10.\r\n\r\n\r\nIn this paper, we make further steps towards the abstraction of\r\nmathematical clauses, formulas and proof states. We present a network that is invariant not only\r\nunder renaming of variables, but also under renaming of arbitrary function and predicate\r\nsymbols. It is also invariant under replacement of the symbols by their negated versions.\r\nThis is achieved by a novel conversion of the input formulas into a hypergraph, followed by a \r\nparticularly designed \r\ngraph neural network (GNN) capable of maintaining the invariance under negation. \r\nWe experimentally demonstrate in three case studies\r\nthat the network works well on data \r\ncoming from automated theorem proving tasks.\r\n\r\n\r\nThe paper is structured as follows. We first formally describe our network architecture in\r\nSection ||SYMBOLTOKEN|| and discuss its invariance properties\r\nin Section ||SYMBOLTOKEN|| We describe an experiment using the\r\nnetwork for guiding  in Section ||SYMBOLTOKEN|| and\r\ntwo experiments done on a fixed dataset in\r\nSection ||SYMBOLTOKEN|| Section ||SYMBOLTOKEN|| contains the\r\nresults of these three experiments.\r\n\r\n\r\n", {}], "Network Architecture for Invariant Embedding": ["\r\n\r\nThis section describes the design and details of the proposed neural architecture for invariant embeddings.\r\n The architecture gets as its input a set of clauses  C. \r\nIt outputs an embedding for each of the clauses in  C, each literal and subterm and each function and predicate\r\nsymbol present in  C. The process consists of initially\r\nconstructing a hypergraph out of the given set of clauses, and then\r\nseveral message passing layers on the hypergraph. In Section ||SYMBOLTOKEN|| we first explain the construction of a hypergraph from the input clauses. The details of the message passing are explained in Section ||SYMBOLTOKEN|| Construction\r\n\r\nWhen converting the clauses to the graph, we aim to capture as much relevant structure as possible. We roughly convert the tree structure of the terms to a circuit by sharing variables, constants and also bigger terms. The graph will be also interconnected through special nodes representing function symbols.\r\nLet ||SYMBOLTOKEN|| c denote the number of clauses, and let the clauses be\r\n C ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ..., ||SYMBOLTOKEN|| c}. Similarly, let\r\n S ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ..., ||SYMBOLTOKEN|| s} denote all the function and\r\npredicate symbols occurring at least once in the given set of clauses,\r\nand  T ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ..., ||SYMBOLTOKEN|| t} denote all the\r\nsubterms and literals occurring at least once in the given set of\r\nclauses. Two subterms are considered to be identical (and therefore\r\nrepresented by a single node) if they are constructed the same way\r\nusing the same functions and variables. If ||SYMBOLTOKEN|| is a negative\r\nliteral, the unnegated form of ||SYMBOLTOKEN|| is not automatically added to\r\n T but all its subterms are.\r\n\r\nThe sets  C,  S,  T represent the nodes of our\r\nhypergraph. The hypergraph\r\nwill also contain two sets of edges: Binary ||SYMBOLTOKEN|| C\u00d7 T between clauses and\r\nliterals, and 4-ary oriented labeled edges ||SYMBOLTOKEN|| st\u2282 S\u00d7 T\u00d7( ||SYMBOLTOKEN|| \r\nHere ||SYMBOLTOKEN|| is a specially created and added term no e disjoint from all actual terms and serving in the arity-related encodings described below. The label is present at the last position of the 5-tuple. \r\nThe set ||SYMBOLTOKEN|| contains all\r\nthe pairs ||SYMBOLTOKEN|| T_j) where ||SYMBOLTOKEN|| is a literal contained in ||SYMBOLTOKEN|| Note that this encoding makes the order of the literals in the clauses irrelevant, which corresponds to the desired semantic behavior.\r\n\r\nThe set ||SYMBOLTOKEN|| is constructed by the following\r\nprocedure applied to every\r\nliteral or subterm ||SYMBOLTOKEN|| that is not a variable. If ||SYMBOLTOKEN|| is a\r\nnegative literal, we set ||MATHEQUATION|| and interpret ||SYMBOLTOKEN|| as\r\nT_i ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| otherwise we set ||MATHEQUATION|| interpret ||SYMBOLTOKEN|| as ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| where ||SYMBOLTOKEN|| S,  n is the arity of ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| T. If ||SYMBOLTOKEN|| we add ||SYMBOLTOKEN|| to ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| we add ||SYMBOLTOKEN|| to ||SYMBOLTOKEN|| finally, if ||SYMBOLTOKEN|| 2, we extend ||SYMBOLTOKEN|| by\r\nall the tuples ||SYMBOLTOKEN|| for ||SYMBOLTOKEN|| encoding is used instead of just ||SYMBOLTOKEN|| to (reasonably) maintain th  order of function and predicate arguments.\r\nFor example, for two non-isomorphic (i.e., differently encoded) terms ||SYMBOLTOKEN|| and ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| will be encoded differently than ||SYMBOLTOKEN|| Note that even this encoding does not capture the complete information about the argument order.\r\nFor example, the term ||SYMBOLTOKEN|| would be encoded the same way as ||SYMBOLTOKEN|| \r\nWe consider such information loss acceptable.\r\nFurther note that the sets ||SYMBOLTOKEN|| E_st, and the derived sets labeled F (explained below) are in fact multisets in our implementation. We present them using the set notations here for readability. \r\n", {"DEFAULT": ["", {}], "Message Passing": ["\r\nBased on the hyperparameters L (number of layers), and ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| s^i, ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| for ||SYMBOLTOKEN|| (dimensions of\r\nvectors), we construct ||SYMBOLTOKEN|| c, ||SYMBOLTOKEN|| s,\r\nand ||SYMBOLTOKEN|| t. First we ||SYMBOLTOKEN|| s_0,j and ||SYMBOLTOKEN|| by learned constant vectors for every type\r\nof clause, symbol, or term. By a \"type\" we mean \r\nan attribute based on the underlying task, see\r\nSection ||SYMBOLTOKEN|| for an example. To preserve invariance\r\nunder negation (see Section ||SYMBOLTOKEN|| we initialize all\r\npredicate symbols to the zero vector.\r\n\r\nAfter the initialization, we propagate through\r\nL message-passing layers. The\r\ni-th layer will output vectors ||SYMBOLTOKEN|| s_i,j and ||SYMBOLTOKEN|| values in the last layer, that is ||SYMBOLTOKEN|| s_L,j ||SYMBOLTOKEN|| are considered to be the output of the network.\r\nThe basic idea of the message passing layer is to propagate information from a node to all its neighbors related by ||SYMBOLTOKEN|| and ||SYMBOLTOKEN|| while recognizing the \"direction\" in which the information came. \r\nAfter this, we \r\nreduce the incoming data to a finite dimension using a \r\nreduction function (defined below)\r\nand propagate through standard\r\nneural layers.[Mostly implemented using the ReLU activation function.]The symbol nodes ||SYMBOLTOKEN|| need particular care, because they can represent two predicate symbols at once: if ||SYMBOLTOKEN|| represents a predicate symbol P, then ||SYMBOLTOKEN|| represents the predicate symbol  P. To preserve the polarity invariance, the symbol nodes \r\nare\r\ntreated slightly differently.\r\n\r\nIn the following we first provide the formulas describing the computation. The\r\nsymbols used in them are explained ||SYMBOLTOKEN|| &= (\r\n  ||SYMBOLTOKEN|| c ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| c\u00b7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| +\r\n  ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| (\r\n  ||SYMBOLTOKEN|| s\u00b7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN||  ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| +\r\n  ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| g\r\n  ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| -3pt\r\n  ||SYMBOLTOKEN|| ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| &= ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| (\r\n  ||SYMBOLTOKEN|| t ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| t\u00b7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN||  -3pt\r\n  ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| all the B symbols represent learnable vectors (biases), and all the\r\nM symbols represent learnable matrices. Their sizes are listed in Fig. ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| c : ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| : ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| : ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| t : ||SYMBOLTOKEN|| t\r\n ||SYMBOLTOKEN|| c         &: ||SYMBOLTOKEN|| c\u00d7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN||       &: ||SYMBOLTOKEN|| c\u00d7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| s         &: ||SYMBOLTOKEN|| s\u00d7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| t         &: ||SYMBOLTOKEN|| t\u00d7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN||       &: ||SYMBOLTOKEN|| t\u00d7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN||       &: ||SYMBOLTOKEN|| s\u00d7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN||     &: ||SYMBOLTOKEN|| s\u00d7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN||     &: ||SYMBOLTOKEN|| t\u00d7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| &: ||SYMBOLTOKEN|| t\u00d7 ||SYMBOLTOKEN|| tSizes of learnable biases and matrices for ||SYMBOLTOKEN|| and ||SYMBOLTOKEN|| a reduction\r\noperation ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| where all ||SYMBOLTOKEN|| are vectors of\r\nthe same dimension n, we mean the vector of dimension 2n obtained\r\nby concatenation of ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| and ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| The\r\nmaximum and average operation are performed point-wise. We also\r\nuse another reduction operation  defined in the same way except\r\ntaking ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| I(u_i) instead of just\r\nmaximum. This makes  commute with multiplication by -1.\r\nIf a reduction operation obtains an empty input (the indexing set is\r\nan empty set), the result is the zero vector of the expected size.\r\n\r\nWe construct sets ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| and ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| on ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| based on ||SYMBOLTOKEN|| where\r\nj_ ||SYMBOLTOKEN|| c, ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| t, and ||SYMBOLTOKEN|| \r\nInformally  the set  ||SYMBOLTOKEN|| contains the indices related to type  y for message passing, given the j-th receiving node of type  ||SYMBOLTOKEN|| &= {a : ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| {a : ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| {(a,b,c,g) : ||SYMBOLTOKEN|| T_a, ||SYMBOLTOKEN|| T_c, ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| {(a,b,c,g) : ||SYMBOLTOKEN|| T_j, ||SYMBOLTOKEN|| T_b, ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| {(a,b,c,g) : ||SYMBOLTOKEN|| T_a, ||SYMBOLTOKEN|| T_b, ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| {(a,b,c,g) : ||SYMBOLTOKEN|| T_a, ||SYMBOLTOKEN|| T_j, ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| E_st can contain a dummy node ||SYMBOLTOKEN|| on the third and fourth positions, following ||SYMBOLTOKEN|| or ||SYMBOLTOKEN|| in the message passing layer may lead us to a non-existing vector ||SYMBOLTOKEN|| In that case, we just take the zero vector of dimension ||SYMBOLTOKEN|| t.\r\n\r\nAfter L message passing layers, we obtain the embeddings ||SYMBOLTOKEN|| s_L,j, ||SYMBOLTOKEN|| of the clauses ||SYMBOLTOKEN|| symbols ||SYMBOLTOKEN|| and terms and literals ||SYMBOLTOKEN|| respectively.\r\n\r\n\r\n", {}]}], "Invariance Properties": ["\r\n\r\nBy the design of the network, it is apparent that the output is\r\ninvariant under the names of the symbols. Indeed, the names are used only\r\nfor determining which symbol nodes and term nodes should be the same\r\nand which should be different.\r\n\r\nIt is also worth noticing that the network is invariant under\r\nreordering of literals in clauses, and under reordering of clauses.\r\nMore precisely, if we reorder the ||SYMBOLTOKEN|| ..., ||SYMBOLTOKEN|| c, then the ||SYMBOLTOKEN|| ..., ||SYMBOLTOKEN|| c are reordered accordingly, and\r\nthe values ||SYMBOLTOKEN|| t_i,j do not change if they still correspond\r\nto the same symbols and terms (they could be also rearranged in\r\ngeneral). This property is clear from the fact that there is no\r\nordered processing of the data, and the only way how literals are\r\nattributed to clauses is through graph edges which are also unordered.\r\nFinally, the network is also designed to preserve the symmetry under\r\nnegation. More precisely, consider replacing every occurrence of a predicate\r\nsymbol ||SYMBOLTOKEN|| by the predicate symbol  ||SYMBOLTOKEN|| in every clause ||SYMBOLTOKEN|| every literal ||SYMBOLTOKEN|| Then the vectors ||SYMBOLTOKEN|| t_i,j do not\r\nchange, the vectors ||SYMBOLTOKEN|| do not change either for all\r\nj ||SYMBOLTOKEN|| x, and the vector ||SYMBOLTOKEN|| is multiplied by -1.\r\n\r\nWe show this by induction on the layer i. For layer 0,\r\nthis is apparent since the ||SYMBOLTOKEN|| is a predicate symbol, ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| 0\u20d7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| let us assume that the claim is true for a layer i. \r\nWe follow the computation of the next layer. The symbol\r\nvectors ||SYMBOLTOKEN|| are not used at all in the computation of ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| remains the same. For ||SYMBOLTOKEN|| where ||SYMBOLTOKEN|| x, we\r\ndon't use ||SYMBOLTOKEN|| in the formula, and the signs have not changed ||SYMBOLTOKEN|| Therefore ||SYMBOLTOKEN|| remains the same.\r\nWhen computing ||SYMBOLTOKEN|| we multiply every ||SYMBOLTOKEN|| with the\r\nappropriate sign (denoted g in the formula). Since we have replaced every\r\noccurrence of ||SYMBOLTOKEN|| by  ||SYMBOLTOKEN|| and kept the other symbols,\r\nthe sign g is multiplied by -1 if and only if c ||SYMBOLTOKEN|| x, and\r\ntherefore the product does not change.\r\nFinally, when computing ||SYMBOLTOKEN|| we follow the formula ||MATHEQUATION||  ||SYMBOLTOKEN|| s\u00b7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN||  ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| depends only on values ||SYMBOLTOKEN|| and therefore\r\nwas not changed. We can rewrite the formula ||MATHEQUATION||  ||SYMBOLTOKEN|| s\u00b7 ||SYMBOLTOKEN|| ||SYMBOLTOKEN||  ||SYMBOLTOKEN||  ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| is because , addition, matrix multiplication, and the\r\nreduction function  are compatible with multiplication by -1.\r\nIn fact, except  they are all linear, thus compatible with\r\nmultiplication by any constant, and  is an odd function.\r\nThe second formula for ||SYMBOLTOKEN|| can be also seen as a formula\r\nfor minus the value of the\r\noriginal ||SYMBOLTOKEN|| since ||SYMBOLTOKEN|| is the original value ||SYMBOLTOKEN|| and (-g) is the original value of g. ||SYMBOLTOKEN|| was multiplied by -1.\r\n\r\n\r\n", {}], "Guiding a Connection Tableaux Prover": ["\r\n\r\nOne of the most important uses\r\nof machine learning in theorem\r\nproving is guiding the inferences done by\r\nthe automating theorem\r\nprovers. The first application of our proposed model is to guide the\r\ninferences performed by the  prover OB03. This line of work\r\nfollows our previous experiments with this prover using the XGBoost system\r\nfor guidance KaliszykUMO18. In this section, we first give a\r\nbrief description of the\r\n prover, then we explain how we fit our network to the  prover, and\r\nfinally discuss the i teraction between the network and the Monte-Carlo\r\nTree Search that we use.\r\nThe  prover attempts to prove a given first-order logic problem by first\r\ntransforming its negation to a clausal form and then finding a set of instances of\r\nthe input clauses that is unsatisfiable.  proves the\r\nunsatisfiability by building a connection tableaux, i.e. a tree,[In some implementations\r\nthis is a rooted forest, as there can be multiple literals in the start clause.]where\r\nevery node contains a literal of the following properties.\r\n\r\n  * The root of the tree is an instance of a given initial clause.\r\n  \r\n  * The children of every non-leaf node are an instance of an input clause\r\n    (we call such clauses\r\n    axioms). Moreover, one of the child literals must be complementary\r\n    to the node.\r\n  \r\n  * Every leaf node is complementary to an element of its path.\r\n\r\n\r\n\r\n\r\n\r\nThe tree is built during the proof process which involves\r\nautomatic computation of substitutions using unification. Therefore the only\r\ndecisions that have to be m de are \"which axiom should be used for\r\nwhich node?\". In particular,  starts with the initial\r\nclause and in every step, it selects the left-most unclosed (open) leaf. If the\r\nleaf can be unified with an element of the path, the unification is\r\napplied. Otherwise, the leaf has to be unified with a literal in an\r\naxiom, and a decision, which literal in which axiom to use, has to be\r\nmade. The instance of the axiom is then added to the tree and the\r\nprocess continues until the entire tree is closed (i.e., the prover\r\nwins, see Fig. ||SYMBOLTOKEN|| or there is no remaining available move (i.e., the prover\r\nloses). As most branches are infinite, additional limits are introduced\r\nand the prover also loses if such a limit is reached.\r\nIn our experiments, we use a version of the prover with two additional\r\noptimizations: lemmata and regularization, originally proposed by Otten DBLP:journals/aicom/Otten10.\r\n\r\n\r\n\r\n\r\n\r\nTo guide the proof search (Fig. ||SYMBOLTOKEN|| i.e. to select the next action,\r\nwe use Monte Carlo Tree Search with policy and value, similar to the AlphaZero silver2017mastering algorithm. This\r\nmeans that the trainable model should take a  state as its\r\ninput, and return estimated value of the state, i.e., the probability that the\r\nprover will win, and the action logits, i.e., real numbers assigned to every\r\navailable action. The action probabilities are then computed from action\r\nlogits using the softmax function.\r\n\r\nTo process the  state with our network, we first need to\r\nconvert it to a list of clauses. If there are A axioms, and a\r\npath of length P, we give the network the ||SYMBOLTOKEN|| clauses: every\r\naxiom is a clause and every element in the path is a clause consisting of\r\none literal. The last clause given to the network consists of all\r\nthe unfinished goals, both under the current path and in earlier\r\nbranches. This roughly corresponds to the set of clauses from which we\r\naim to obtain the contradiction. The initial labels of the clauses can be\r\ntherefore of 3 types: a clause originating from a goal, a member of a path, or an\r\naxiom. Each of these types represent a learnable initial vector of\r\ndimension 4.\r\n\r\nThe symbols can be of two types: predicates and functions, their\r\ninitial value is represented by a single real number: zero for\r\npredicates, and a learnable number for functions. For term nodes,\r\nvariables in different axioms are always considered to be different,\r\nand they are also considered to be different from the variables in the\r\ntableaux (note that unification performs variable renaming). Variables in the tableaux are shared among the path and the\r\ngoals. Every term node can be of four types: a variable in an axiom,\r\na variable in the tableaux, a literal, or another term. The term nodes have\r\ninitial dimension 4.\r\n\r\nAfterwards, we propagate through five message passing layers, with\r\ndimensions ||SYMBOLTOKEN|| ||MATHEQUATION|| ||SYMBOLTOKEN|| = ||SYMBOLTOKEN|| ||MATHEQUATION|| obtaining ||SYMBOLTOKEN|| s_5,j and ||SYMBOLTOKEN|| we consider all the ||SYMBOLTOKEN|| vectors, apply\r\na hidden layer of size 64 with ReLU activation to them, apply\r\nthe  reduction and use one more hidden layer of size 64 with ReLU\r\nactivation. The final value is then computed by a linear\r\nlayer with sigmoid activation.\r\n\r\nGiven the general setup, we now describe how we compute the logit for an action corresponding to the use of ||SYMBOLTOKEN|| and complementing its literal ||SYMBOLTOKEN|| with the current goal. ||SYMBOLTOKEN|| represents the clause of all the remaining goals. We ||SYMBOLTOKEN|| t_5,j and ||SYMBOLTOKEN|| process it with a hidden layer\r\nof size 64 with ReLU activation, and then use a linear output layer\r\n(without the activation function).\r\n\r\nWith the  prover, we perform four solving and training\r\niterations. In every solving iteration, we attempt to solve every problem in\r\nthe dataset, generating training data in the meantime. The training\r\ndata are then used for training the network, minimizing the\r\ncross-entropy with the target action probabilities and the MSE of the\r\ntarget value of every trained state. Every solving iteration therefore\r\nproduces the target for action policy, and for value estimation, that are used\r\nfor the following training.\r\n\r\nThe solving iteration number 0 (we also call it \"bare prover\") is\r\nperformed differently from the \r\nfollowing ones. We use the prover without guidance, performing random\r\nsteps with the step limit 200 repeatedly within a time limit.\r\nFor every proof we find, we run the random solver again from every\r\npartial point in the proof, estimating the probabilities that the\r\nparticular actions will lead to a solution. This is our training data\r\nfor action probabilities. In order to get training da a for value, we take all the states which we\r\nestimated during the computation of action probabilities. If the\r\nprobability of finding a proof is non-zero in that state, we give it value\r\n1, otherwise, we give it value 0.\r\n\r\nEvery other solving iteration is based on the network guidance in an\r\nMCTS setting, analogously to AlphaZero silver2017mastering and\r\nto the  system KaliszykUMO18. In order to decide\r\non the action, we first built a game tree of size 200 according to the PUCT formula\r\n\r\nU(s,a) ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| the prior probabilities and values are given by the network, and\r\nthen we select the most visited node (performing a bigstep). This contrasts to the previous\r\nexperiment with a simpler clasifier KaliszykUMO18 where\r\nevery decision node is given 2000 new expansions (in addition to the\r\nexpansions already performed on the node).\r\nAdditionally a limit of game steps of 200 has been added.\r\nThe target probabilities of any state in every bigstep is proportional\r\nthe number of visit counts of the appropriate actions in the tree\r\nsearch. The target value in these states is boolean depending on\r\nwhether the proof was ultimately found or not.\r\n\r\n\r\n", {}], "DeepMath Experiments": ["\r\nDeepMath is a dataset developed for the\r\nfirst deep learning experiments with pre ise selection IrvingSAECU16ju on the Mizar40\r\nproblems KaliszykU13b. Unlike other datasets such as\r\nHOLStep DBLP:conf/iclr/KaliszykCS17, DeepMath contains first-order formulas\r\nwhich makes it more suitable for our network. We used the dataset for\r\ntwo experiments -- premise selection (Section ||SYMBOLTOKEN|| and recovering symbol names from the structure, i.e. symbol guessing (Section ||SYMBOLTOKEN|| Selection\r\n\r\nDeepMath contains 32524 conjectures, and a balanced list of positive\r\nand negative premises for each conjecture. There are on average 8\r\npositive and 8 negative premises for each conjecture. The task we consider first is to\r\ntell apart the positive and negative premises.\r\n\r\nFor our purposes, we randomly divided the conjectures into 3252 testing\r\nconjectures and 29272 training conjectures. For every conjecture,\r\nwe clausified the negated conjecture together with\r\nall its (negative and positive) premises, and gave them all as input to the\r\nnetwork (as a set of clauses). We kept the hyperparameters \r\nfrom the  experiment. There are two differences. First, there\r\nare just two types of clause nodes: negated conjectures and premises.\r\nSecond, we consider just one type of variable nodes.\r\n\r\nTo obtain the output, we reduce (using the  function introduced\r\n in Section ||SYMBOLTOKEN|| the clause nodes belonging to the conjecture and we do the same\r\nalso for each premise. The the two results are concatenated and pushed through a\r\nhidden layer of size 128 with ReLU activation. Finally,\r\nan output layer (with sigmoid activation) is applied to obtain the\r\nestimated probability of the premise being positive (i.e., relevant for the conjecture).\r\n\r\n\r\n", {"Message Passing": ["", {}], "Recovering Symbol Names from the Structure": ["\r\nIn addition to the standard premise selection task, our setting is\r\nalso suitable for defining and experimenting with a novel interesting\r\ntask: guessing the names of the symbols from the structure of the formula.\r\nIn particular, since the network has no information about the names of the symbols, \r\nit is interesting to see how much the trained system can correctly\r\nguess the exact names of the function and predicates symbols based just on the problem\r\nstructure.\r\n\r\nOne of the interesting uses is for conjecturing by\r\n  analogies GauthierKU16, i.e., creating new conjectures by\r\ndetecting and following alignments of various mathematical theories\r\nand concepts. Typical examples include the alignment between the\r\ntheories of additive and multiplicative groups, complex and real\r\nvector spaces, dual operations such as join and meet in lattices, etc.\r\nThe first systems used for alignment detection have been so far\r\nmanually engineered GauthierK19, whereas in our setting such\r\nalignment is just a byproduct of the structural learning.\r\n\r\nThere are two ways how a new unique\r\nsymbol can arise during the clausification process.\r\nEither as a Skolem function, or as a new definition (predicate)\r\nthat represents parts of the original formulas.\r\nWe performed two experiments based on how\r\nsuch new symbols are handled. We either ignore them, and train the neural\r\nnetwork on the original (labeled) symbols only, or we give to all the\r\nnew symbols the common labels skolem and\r\ndef. Table ||SYMBOLTOKEN|| shows the frequencies of\r\nthe five most common symbols in the DeepMath dataset after the\r\nclausification. Note that the newly introduced skolems and defin t ons\r\naccount for almost 40% of the data.\r\n\r\n\r\n\r\n The most common symbols in the clausified DeepMath.\r\n\r\n\r\n\r\n", {}]}], "Experimental Results": ["\r\n", {"Guiding": ["\r\nWe evaluate our neural guided  against rlCoP KaliszykUMO18. Note however, that for both systems we\r\nuse 200 playouts per MCTS decision so the  results presented here are different from KaliszykUMO18. We start with a set of  states with their values and action probabilities coming from the 4595 training \r\nproblems \r\nsolved with the bare random prover.\r\n\r\nAfter training on this set, the MCTS guided\r\nby our network manages to solve 11978 training (160.7% more) and 1322 (159.2% more) testing problems, in total 13300 problems (160.5% more -- Fig. ||SYMBOLTOKEN|| This is\r\nin total\r\n49.1%\r\nmore than  guided by XGBoost  which in the same setup and with the same limits\r\nsolves 8012 training problems, 908 testing problems, and 8920 problems in total. \r\nThe improvement in the first iteration over XGBoost on the training and testing set is 49.5% and 45.6% respectively.\r\n\r\nSubsequent iterations are also much better than for rlCoP, with\r\nslower progress already in third iteration (note that rlCoP also loses problems, starting with\r\n6th iteration).\r\nThe evalu tion ran 100 provers in parallel on multiple CPUs communicating with the network running on a GPU. \r\nReceiving the queries from the prover takes\r\non average 0.1 s, while\r\nthe message-passing layers alone take around 0.12 s per batch.  The\r\ncurrent main speed issue turned out to be the communication overhead\r\nbetween the provers and the network. The average inference step in 100\r\nagents and one network inference took on average 0.57 sec.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", {}], "Premise Selection": ["\r\nIn the first DeepMath experiment with Boolean classification, we obtained testing accuracy of around 80%. We trained the network in 100 epochs on minibatches of size 50. A stability issue can be spotted around the epoch 60 from which the network quickly recovered.\r\nWe cannot compare the results to the standard methods since the dataset is by design hostile to them -- the negatives samples are based on the KNN, so KNN has accuracy even less than 50%. Simpler neural networks were previously tested on the same dataset DBLP:journals/corr/abs-1807-10268reaching accuracy 76.45% .\r\n\r\n", {}], "Recovering Symbol Names from the Structure": ["\r\nFor guessing of symbol names, we used minibatches consisting only of\r\n10 queries, and trained the network for 50 epochs. When training and\r\nevaluating on the labeled symbols only, the testing accuracy reached\r\n65.27% in the last epoch. Note that this accuracy is measured on\r\nthe whole graph, i.e., we count both the symbols of the conjecture and of the\r\npremises. When training and evaluating also on the\r\ndef and skolem symbols, the testing accuracy reached\r\n78.4% in the last epoch -- see Fig. ||SYMBOLTOKEN|| g r a p h i c s ||SYMBOLTOKEN|| and training accuracy on the label guessing task on the DeepMath dataset.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nWe evaluate the symbol\r\nguessing (without considering  def and skolem) in more detail on the 3252 test problems and their conjectures.\r\nIn particular, for each of these problems and each conjecture symbol,\r\nthe evaluation with the trained network gives a list of candidate\r\nsymbol names ranked by their probability.  We first compute the number\r\nof cases where the most probable symbol name as suggested by the\r\ntrained network is the correct one.  This happens in 22409 cases out\r\nof 32196, i.e., in 70% cases.[This differs from the\r\n  testing accuracy of 65.27%\r\n  mentioned above, b cause we only consider the conjecture symbols here.]\r\nA perfect naming of all symbols is achieved for 544 conjectures, i.e.,\r\nin 16.7% of the test cases. Some of the most common analogies\r\nmeasured as the common symbol-naming mistakes done on the test\r\nconjectures are shown in Table ||SYMBOLTOKEN|| Some of the common analogies\r\n\r\n\r\nWe briefly analyze some of the analogies produced by the network predictions.\r\nIn ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| the trained network's best guess correctly labels the symbols\r\nas binary intersection and union (both with probability ca 0.75).\r\nIts second best guess is however also quite probable ||SYMBOLTOKEN|| the union and intersection. This is quite common, probably\r\nbecause dual theorems about these two symbols are frequent in the\r\ntraining data. Interestingly, the second best guess results also in an\r\nprovable conjecture, since it easily follows ||SYMBOLTOKEN|| just by symmetry of equality.\r\n\r\ntheorem :: ||SYMBOLTOKEN|| X, Y, Z being set holds ((X / Y)  (Y / Z))  (Z / X) ||SYMBOLTOKEN|| ((X  Y) / (Y  Z)) / (Z  X)\r\n\r\nsecond guess:\r\nfor X, Y, Z being set holds ((X  Y) / (Y  Z)) / (Z  X) ||SYMBOLTOKEN|| ((X / Y)  (Y / Z))  (Z / X)\r\nIn ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| trained network has consistently decided to replace the symbols\r\ndefined for complex vector spaces with their analogs defined for real\r\nvector spaces (i.e., those symbols are ranked higher). This is most likely because of the large theory of real\r\nvector spaces in the training data, even though the exact ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| was not among the training data. This again means that the trained network has produced ||SYMBOLTOKEN|| as a new (provable) conjecture.\r\n\r\ntheorem :: ||SYMBOLTOKEN|| V being ComplexLinearSpace for u, v being VECTOR of V\r\nfor W being Subspace of V holds \r\n( u in W iff v ||SYMBOLTOKEN|| W ||SYMBOLTOKEN|| (v - u) ||SYMBOLTOKEN|| W )\r\n\r\ntheorem :: ||SYMBOLTOKEN|| V being RealLinearSpace for u, v being VECTOR of V\r\nfor W being Subspace of V holds \r\n( u in W iff v ||SYMBOLTOKEN|| W ||SYMBOLTOKEN|| (v - u) ||SYMBOLTOKEN|| W  \r\n\r\n\r\nFinally, we show below two examples. The fi st  ne illustrates on theorems ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| and ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| network finding well-known dualities of concepts in lattices (join vs. meet, upper-bounded vs. lower-bounded and related concepts). The second one is an example of a discovered analogy between division and subtraction operations on complex numbers, i.e, conjecturing ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| ||SYMBOLTOKEN|| mptp/7.13.01 ||SYMBOLTOKEN|| :: LATTICE4:15\r\nfor 0L being lower-bounded Lattice \r\nfor B1, B2 being ||SYMBOLTOKEN|| of the carrier of 0L holds \r\n(FinJoin B1) \"\" (FinJoin B2) ||SYMBOLTOKEN|| FinJoin (B1  B2)\r\n\r\nsimilar to:\r\ntheorem Th23: :: LATTICE4:23\r\nfor 1L being upper-bounded Lattice\r\nfor B1, B2 being ||SYMBOLTOKEN|| of the carrier of 1L holds \r\n(FinMeet B1) \"/(\u0308FinMeet B2) ||SYMBOLTOKEN|| FinMeet (B1  B2)\r\n\r\ntheorem :: ||SYMBOLTOKEN|| a, b, s being complex number holds \r\na,b -- s ||SYMBOLTOKEN|| (a - s),(b - s)\r\n\r\nsimilar to:\r\ntheorem :: ||SYMBOLTOKEN|| a, b, s being complex number holds \r\na,b ||MATHEQUATION|| s ||SYMBOLTOKEN|| (a / s),(b / s)\r\n\r\n\r\n", {}]}], "Related Work": ["Early work on combining machine learning with automated theorem\r\nproving includes,\r\ne.g., DBLP:conf/ogai/ErtelSS89,DenzingerFGS99,DBLP:books/daglib/0002958.\r\nMachine learning over large formal corpora created from ITP\r\nlibraries Urban06,MengP08,holyhammer has been used for premi e\r\nselection ||SYMBOLTOKEN|| in strong hammer systems for selecting relevant facts\r\nfor proving new conjectures over large formal\r\nlibraries abs-1108-3446,BlanchetteGKKU16,hh4h4. More recently,\r\nmachine learning has also started to be used to guide the internal\r\nsearch of the ATP systems. In saturation-style provers this has been\r\ndone by feedback loops for strategy\r\ninvention blistr,JakubuvU1 a,SchaferS15 and by using supervised\r\nlearning JakubuvU17a,LoosISK17 to select the  ext given\r\nclause Overbeek:1974:NCA:321812.321814. In the simpler\r\nconnection tableau systems such as  OB03 used here, supervised\r\nlearning has been used to choose the next tableau extension\r\nstep UrbanVS11,KaliszykU15, using Monte-Carlo guided  roof\r\nsearch FarberKU17 and reinforcement\r\nlearning KaliszykUMO18 with fast non-deep learners. Our main evaluation is done in this setting.\r\n\r\nDeep neural networks for classification of mathematical formulae were first\r\nintroduced in the  eepMath experiments IrvingSAECU16ju\r\nwith 1D convolutional networks and LSTM networks.\r\nFor higher-order logic, the HolStep DBLP:conf/iclr/KaliszykCS17 dataset\r\nwas extracted from\r\ninteractive theorem prover HOL Light. 1D convolutional neural networks, LSTM, and their combination were proposed as baselines for the dataset.\r\nOn this dataset a Graph-based neural network was for a firs  time applied to theorem proving in the FormulaNet DBLP:conf/nips/WangTWD17 work.\r\nFormulaNet, like our work, also represents identical\r\nvariables by a single nodes in a graph, being therefore invariant\r\nunder variable renaming. Unlike our network, FormulaNet glues\r\nvariables only and not more complex terms.\r\nFormulaNet is not designed\r\nspecifically for first-order logic, therefore it lacks invariance under\r\nnegation and possibly reordering of clauses and literals.\r\nThe\r\ngreatest difference is however that our network \r\nabstracts over the symbol names\r while FormulaNet learns them individually.\r\n\r\nA different invariance property was proposed in a network for propositional calculus by Selsam et\r\nal. SelsamLBLMD19. This network is invariant under negation,\r order of clauses, and order of literals in clauses, however this \r\nis restricted to propositional logic, where no quantifiers and variables\r\nare present. In the first-order setting, Kucik and\r\nKorovin DBLP:journals/corr/abs-1807-10268 performed experiments with basic neural\r\nnetworks with one hidden layer on the DeepMath dataset.\r\nNeural networks reappeared in state-of-the-art saturation-based proving (E prover) in the work of Loos et al. slgicscklpar17. The considered models included CNNs, LSTMs, dilated con olutions, and tree models.\r The first practical comparison of neural networks, XGBoost and Liblinear in guiding E prover was done by Chvalovsky et al. ChvalovskyJ0U19.\r\nAn alternative to connecting an identifier with all the formulas about it, is to perform definitional embeddings. This has for the first time been done in the context of theorem proving in DeepMath IrvingSAECU16ju, however in a non-recursive way. A fully recursive, but non-deep name-independent encoding has been used and evaluated in HOLyHammer experiments ckju-mcs-hh. Similarity between concepts has been discovered using alignments, see e.g. DBLP:conf/lpar/GauthierK15.\r\nEmbeddings of particular individual logical concepts have been considered as well, for example polynomials AllamanisCKS17 or equations abs-1803-09123.\r\n\r\n\r\n", {}], "Conclusion": ["\r\n\r\nWe presented a neural network for processing mathematical formulae invariant under symbol names, negation and ordering of clauses and their literals, and we demonstrated its learning capabilities in\r\nthree automated reasoning tasks.\r\nIn particular, the network improves over the previous version of \r\nguided by XGBoost by 45.6% on the test set in the first iteration of\r\nlearning-guided proving. It also outperforms earlier methods on the\r\npremise-selection data, and establishes   strong baseline for symbol\r\nguessing. One of its novel uses proposed here and allowed by this\r\nneural architecture is creating new conjectures by detecting and\r\nfollowing alignments of various mathematical theories and\r\nconcepts. This task turns out to be a straigh forward application of the structural\r\nlearning performed by the network.\r\n\r\nPossible future work includes for example integration with state-of-the-art saturation-style provers. \r\nAn interesting next step is also evaluation on a heterogeneous dataset such as TPTP where\r\nsymbols are not used consistently and learning on multiple libraries --\r\ne.g. jointly on HOL and HOL Light as done previously\r\nby DBLP:conf/lpar/GauthierK15 using a hand-crafted alignment\r\nsystem.\r\n\r\n", {}], "Acknowledgements": ["Ol\u0161\u00e1k and Kaliszyk were supported by the ERC Project SMART Starting Grant no. 714034.\r\nUrban was supported by the AI4REASON ERC\r\nConsolidator grant number 649043, and by the Czech project\r\nAI&Reasoning ||SYMBOLTOKEN|| and the European\r\nRegional Development Fund.\r\n\r\nleancop-graph-nn.bbl\r\nWhen converting the clauses to the graph, we aim to capture as much relevant structure as possible. We roughly convert the tree structure of the terms to a circuit by sharing variables, constants and also bigger terms. The graph will be also interconnected through special nodes representing function symbols.\r\n\r\n\n", {}]}	Automated reasoning and theorem proving have recently become major challenges for machine learning. In other domains, representations that are able to abstract over unimportant transformations, such as abstraction over translations and rotations in vision, are becoming more common. Standard methods of embedding mathematical formulas for learning theorem proving are however yet unable to handle many important transformations. In particular, embedding previously unseen labels, that often arise in definitional encodings and in Skolemization, has been very weak so far. Similar problems appear when transferring knowledge between known symbols.  We propose a novel encoding of formulas that extends existing graph neural network models. This encoding represents symbols  only by nodes in the graph, without giving the network any knowledge of the original labels. We provide additional links between such nodes that allow the network to recover the meaning and therefore correctly embed such nodes irrespective of the given labels. We test the proposed encoding in an automated theorem prover based on the tableaux connection calculus, and show that it improves on the best characterizations used so far.  The encoding is further evaluated on the premise selection task and a newly introduced symbol guessing task, and shown to correctly predict 65% of the symbol names.
